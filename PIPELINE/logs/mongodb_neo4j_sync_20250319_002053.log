2025-03-19 00:20:53,608 - root - INFO - Starting MongoDB to Neo4j sync service
2025-03-19 00:20:53,608 - root - INFO - Sync interval: 30 minutes
2025-03-19 00:20:53,609 - root - INFO - Starting full sync job at 2025-03-19 00:20:53.608547
2025-03-19 00:21:01,399 - src.spark.session - INFO - Spark session created successfully
2025-03-19 00:21:01,557 - src.graph.neo4j_client - INFO - Connected to Neo4j database
2025-03-19 00:21:01,594 - src.graph.neo4j_client - INFO - Neo4j schema initialized
2025-03-19 00:21:01,595 - root - INFO - Extracting data from MongoDB...
2025-03-19 00:21:08,616 - src.etl.extract - INFO - Extracted 50 records from Person
2025-03-19 00:21:09,671 - src.etl.extract - INFO - Extracted 10 records from Company
2025-03-19 00:21:10,662 - src.etl.extract - INFO - Extracted 93 records from Loan
2025-03-19 00:21:11,734 - src.etl.extract - INFO - Extracted 57 records from PrimaryApplicant
2025-03-19 00:21:12,695 - src.etl.extract - INFO - Extracted 93 records from Coapplicant
2025-03-19 00:21:13,770 - src.etl.extract - INFO - Extracted 183 records from Reference
2025-03-19 00:21:13,783 - root - INFO - Loading nodes into Neo4j...
2025-03-19 00:21:18,081 - root - ERROR - Error during sync job: [TABLE_OR_VIEW_NOT_FOUND] The table or view `co_applicant` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 38;
'Aggregate [count(1) AS count#281L]
+- 'Filter ('personId = PERSON001)
   +- 'UnresolvedRelation [co_applicant], [], false
Traceback (most recent call last):
  File ".\src\main.py", line 56, in run_sync_job
    person_count = load_persons(spark, person_df, neo4j_client)
  File "C:\Users\ADITI\Desktop\pyspark-pipeline\src\etl\load.py", line 28, in load_persons
    roles = get_entity_roles(spark, person_id)
  File "C:\Users\ADITI\Desktop\pyspark-pipeline\src\etl\transform.py", line 50, in get_entity_roles
    is_coapplicant_row = spark.sql(f"""
  File "C:\Users\ADITI\anaconda3\envs\spark_env\lib\site-packages\pyspark\sql\session.py", line 1631, in sql
    return DataFrame(self._jsparkSession.sql(sqlQuery, litArgs), self)
  File "C:\Users\ADITI\anaconda3\envs\spark_env\lib\site-packages\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "C:\Users\ADITI\anaconda3\envs\spark_env\lib\site-packages\pyspark\errors\exceptions\captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `co_applicant` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 38;
'Aggregate [count(1) AS count#281L]
+- 'Filter ('personId = PERSON001)
   +- 'UnresolvedRelation [co_applicant], [], false

